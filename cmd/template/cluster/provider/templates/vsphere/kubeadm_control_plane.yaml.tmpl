apiVersion: controlplane.cluster.x-k8s.io/v1alpha4
kind: KubeadmControlPlane
metadata:
  labels:
    "release.giantswarm.io/version": "{{ .ReleaseVersion }}"
    "giantswarm.io/cluster": "{{ .Name }}"
    "cluster.x-k8s.io/cluster-name": "{{ .Name }}"
    "giantswarm.io/organization": "{{ .Organization }}"
  name: {{ .Name }}
  namespace: {{ .Namespace }}
spec:
  kubeadmConfigSpec:
    clusterConfiguration:
      apiServer:
        extraArgs:
          cloud-provider: external
      controllerManager:
        extraArgs:
          cloud-provider: external
    files:
    - content: |
        apiVersion: v1
        kind: Pod
        metadata:
          creationTimestamp: null
          name: kube-vip
          namespace: kube-system
        spec:
          containers:
          - args:
            - start
            env:
            - name: vip_arp
              value: "true"
            - name: vip_leaderelection
              value: "true"
            - name: vip_address
              value: 10.0.6.191
            - name: vip_interface
              value: eth0
            - name: vip_leaseduration
              value: "15"
            - name: vip_renewdeadline
              value: "10"
            - name: vip_retryperiod
              value: "2"
            image: plndr/kube-vip:0.3.2
            imagePullPolicy: IfNotPresent
            name: kube-vip
            resources: {}
            securityContext:
              capabilities:
                add:
                - NET_ADMIN
                - SYS_TIME
            volumeMounts:
            - mountPath: /etc/kubernetes/admin.conf
              name: kubeconfig
          hostNetwork: true
          volumes:
          - hostPath:
              path: /etc/kubernetes/admin.conf
              type: FileOrCreate
            name: kubeconfig
        status: {}
      owner: root:root
      path: /etc/kubernetes/manifests/kube-vip.yaml
    initConfiguration:
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: external
        name: '{{ `{{ ds.meta_data.hostname }}` }}'
    joinConfiguration:
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: external
        name: '{{ `{{ ds.meta_data.hostname }}` }}'
    preKubeadmCommands:
    - hostname "{{ `{{ ds.meta_data.hostname }}` }}"
    - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
    - echo "127.0.0.1   localhost" >>/etc/hosts
    - echo "127.0.0.1   {{ `{{ ds.meta_data.hostname }}` }}" >>/etc/hosts
    - echo "{{ `{{ ds.meta_data.hostname }}` }}" >/etc/hostname
    useExperimentalRetryJoin: true
    users:
    - name: capv
      {{ with .SSHPublicKeys }}
      sshAuthorizedKeys:
      {{ range . }}
      - "{{ . }}"
      {{ end }}
      {{ end }}
      sudo: ALL=(ALL) NOPASSWD:ALL
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1alpha4
      kind: VSphereMachineTemplate
      name: {{ .Name }}
  replicas: 1
  rolloutStrategy:
    rollingUpdate:
      maxSurge: 1
    type: RollingUpdate
  version: {{ .KubernetesVersion }}
